---
title: "p8105_hw5_cm3341"
author: "Carolina Montes Garcia"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true 
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1
Probabily that two people in the same room share their birthday. 
```{r}
bday_sim = function(n) {

  bdays = sample(1:365, size = n, replace = TRUE)
  
  duplicate = length(unique(bdays)) < n

  return(duplicate)
  
}


```

Now I will run the simulation for sample sizes 2 and 50. I then run these simulations 1000 times and plot the probability of 2 people having the same birthday in the same room for each group size.

```{r}
sim_res = 
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n, bday_sim)) |> 
  group_by(n) |> 
  summarize(prob = mean(res))

sim_res |> 
  ggplot(aes(x = n, y = prob )) + 
  geom_line()
```


## Problem 2

Create a function that generates values for a normal distribution and a two sided t-test.
```{r}
sim_mean_sd = function(n = 30, mu, sigma = 5) {
  
  sim_data = rnorm(n, mu, sigma)

  t_test = t.test(sim_data, y = NULL, mu = mu, alternative = "two.sided", conf.level = 0.95) %>% 
    broom::tidy() %>% 
    janitor::clean_names() %>% 
    select(p_value, estimate)

 out_df = 
   tibble(
    true_mean = mu,
    p_value = t_test$p_value,
    est_mean = t_test$estimate
    )

 return(out_df)
}
```

Now I simulate 
```{r, eval = FALSE}
output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_mean_sd(30, 0, 5)
}

sim_results = bind_rows(output)


```

Now I iterate the function for different mu values.

```{r}

sim_res = 
  expand_grid(
    mu = c(1, 2, 3, 4, 5, 6),
    iter = 1:5000
  ) %>%  
  mutate(samp_res = map(mu, \(x) sim_mean_sd(n = 30, x, sigma = 5))   ) %>%  
  unnest(samp_res) %>% 
  select(mu, p_value, est_mean)

```


Plot 1
```{r}
power_res =
  sim_res %>%
  group_by(mu) %>%
  summarize(
    power = mean(p_value < 0.05)
  )

power_res %>% 
  ggplot(aes(x = mu, y = power)) +
  geom_line()
```


Plot 2

```{r}

sim_res %>% 
  group_by(mu) %>% 
  ggplot(aes(x = as.factor(mu), y = est_mean, fill= mu))+
  geom_boxplot()

```


Plot 3
```{r}
sim_res %>% 
  group_by(mu) %>% 
  filter(p_value<0.05) %>% 
  ggplot(aes(x = as.factor(mu), y = est_mean, fill= mu))+
  geom_boxplot()
```
Is the sample average of mu hat across tests for which the null is rejected approximately equal to the true value of mu? Why or why not?

Interpretation: The sample average of mu hat across test for which the null is rejected is not approximately equal to the true value of mu because in the cases of significance, mu hat would be found on the tail ends of the normal distribution. 


## Problem 3

Import data after downloading the csv file from github. Clean and tidy data.

```{r}
hom_data = 
  read_csv("data/homicide-data.csv") %>%  
  mutate(
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")) |> 
  select(resolved, victim_age, victim_race, victim_sex)
```

This dataset contains observations for 52,000 homicides across 50 of the US's largest cities. Data is from the past decade. The dataset includes demographic variables about victims (i.e., name, age, rage, sex), along with date and location information for where the homicide took place, and whether an arrest took place. 

Create a city/state variable.
```{r}

hom_data = 
  hom_data %>%
  mutate(city_state = paste(city, state, sep = ", "))
```

Summary table of homicides, including unresolved homicides, grouped by city/state.
```{r}
homs_by_city =
  hom_data %>%
  group_by(city_state) %>%
  summarize(
    homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  ) %>%
  arrange(desc(homicides))

knitr::kable(homs_by_city)
```

Filter for Baltimore, MD and count number of resolved vs. unresolved homicides.
```{r}
homs_baltimore = 
  hom_data %>% 
  filter(city_state == "Baltimore, MD") %>% 
  mutate(
    unsolved = as.numeric(disposition %in% c("Closed without arrest", "Open/No arrest")),
    resolved = as.numeric(disposition == "Closed by arrest")
  ) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved)
  )

```

Prop.test for homicides in Baltimore, MD

```{r}
prop_test_baltimore = 
  prop.test(
  x = homs_baltimore$unsolved_homicides,
  n = homs_baltimore$total_homicides
) %>% 
  broom::tidy() 

prop_test_table = 
  prop_test_baltimore%>% 
  mutate(estimate_prop = exp(estimate)) %>% 
  select(estimate_prop, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)

prop_test_table
```

